general:
  name: "evolve.ai"
  description: "This is the configuration file that contains information about the models and infra used by the evolution agent"

# This contains the model information for various agents
# in our multi agentic system
insights_agent_model_information:
  # this is the prompt template that the insights agent uses
  insights_agent_prompt: prompt_templates/log_curator_base_prompt.txt
  # Represents the model id that the agent will use within the system
  # as an deep agent model
  model_id: us.anthropic.claude-sonnet-4-20250514-v1:0
  # Represents the inference parameters that the foundation model
  # uses at runtime during inference
  inference_parameters:
    temperature: 0.1
    max_tokens: 2048
    top_p: 0.92
    caching: true

# This section contains information used by the main
# agent to implement efficient context engineering of
# model context and tool results
context_engineering_info:
  # Summarization middleware information
  # this is to automatically summarize conversation
  # history when approaching token limits
  summarization_middleware: 
    # this is the model that will be used as a summarization
    # model
    model: us.anthropic.claude-3-5-haiku-20241022-v1:0
    # these ate the number of messages to keep after the summarization
    messages_to_keep: 20
    # temperature used for the summarization middleware
    temperature: 0.1
    # this is the token threshold at which the summarization is instantiated
    max_tokens_before_summary: 4000
    # max tokens
    max_tokens: 2000
    # This is the path to the summarization prompt
    summary_prompt: prompt_templates/context_engineering/langsmith/summarization_base_prompt.txt
    summary_prefix: "Previous conversation summary"

  # Token threshold for context management
  # Used by both TokenLimitCheckMiddleware and ToolResponseSummarizer
  # to ensure consistent behavior across all context management components
  # When messages or tool responses exceed this threshold, they are summarized
  token_threshold: 100000  # 100k tokens

# Deep Research Agent Configuration
# This agent analyzes error patterns from insights AND performs internet research
# to find solutions and best practices - it's a single unified agent
deep_research_agent_model_information:
  # Prompt template for the deep research agent (handles both error analysis and internet search)
  deep_research_agent_prompt: prompt_templates/evolution_error_analysis.txt
  # Model ID for deep research agent
  model_id: us.anthropic.claude-sonnet-4-20250514-v1:0
  # Inference parameters for deep research
  inference_parameters:
    temperature: 0.1
    max_tokens: 8192
    top_p: 0.92
    caching: true
  # Internet search configuration
  internet_search:
    max_results: 5
    topic: "general"  # Options: general, news, finance
    include_raw_content: false
  # Output configuration
  output:
    default_output_dir: "reports"
    default_file_format: "md"  # markdown format
  # Agent repository access configuration
  # The deep research agent can access either a local repository or clone from GitHub
  agent_repository:
    type: "local"  # Options: "local" or "github"
    local_path: "/Users/madhurpt/Desktop/self-healing-agent"  # Path to local agent repository
    github_url: ""  # GitHub URL if type is "github" (e.g., https://github.com/user/repo)

# Routing Configuration
# Controls conditional routing between insights agent and deep research agent
routing_configuration:
  # Small, fast model for routing decisions
  router_model_id: us.anthropic.claude-3-5-haiku-20241022-v1:0
  # Inference parameters for router
  inference_parameters:
    temperature: 0.1
    max_tokens: 500
    top_p: 0.92
  # Routing prompt template path
  router_prompt_path: prompt_templates/routing_decision_prompt.txt